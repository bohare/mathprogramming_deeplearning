{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.array([[[1, 1, 1, 1, 1, 2],\n",
    "                 [1, 2, 3, 4, 0, 0],\n",
    "                 [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [1, 2, 3, 4, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [1, 2, 3, 4, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [1, 2, 3, 4, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 4, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 4, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 5, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 5, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 5, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 5, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 6, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 6, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 6, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 6, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "               \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [1, 3, 2, 3, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [1, 3, 2, 3, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [1, 3, 2, 3, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [1, 3, 2, 3, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 3, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 1, 2],\n",
    "                [2, 1, 3, 3, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [2, 1, 3, 3, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [2, 1, 3, 3, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [2, 1, 3, 3, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [2, 1, 3, 3, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-2, -3, -4, -2, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-2, -3, -4, -9, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-2, -3, -4, -2, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-2, -3, -4, -2, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-2, -3, -4, -3, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-2, -3, -4, -3, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-2, -3, -6, -5, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-2, -3, -6, -5, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-2, -3, -6, -5, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-2, -3, -6, -5, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-3, -2, -6, -5, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-3, -2, -6, -5, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-3, -2, -6, -5, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-3, -2, -6, -5, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-3, -2, -6, -11, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 1, 1, 2, 2],\n",
    "                [-3, -2, -6, -11, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [-3, -2, -6, -11, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [2, 1, 3, 4, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [2, 1, 3, 4, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [2, 1, 3, 4, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [3, 1, 2, 5, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [3, 1, 2, 5, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [3, 1, 2, 5, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [3, 1, 2, 5, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [1, 2, 3, 3, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [1, 2, 3, 3, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [3, 4, 1, 5, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [3, 4, 1, 5, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [3, 4, 1, 5, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [3, 4, 1, 5, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [4, 3, 5, 7, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [4, 3, 5, 7, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [4, 3, 5, 7, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [4, 3, 5, 7, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [2, 3, 1, 6, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 1, 2],\n",
    "                [2, 3, 1, 6, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [2, 3, 1, 6, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [2, 3, 1, 6, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [2, 3, 1, 6, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [2, 3, 1, 6, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [1, 3, 2, 3, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [1, 3, 2, 3, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [1, 3, 2, 3, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [1, 3, 2, 3, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [1, 3, 2, 5, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [1, 3, 2, 5, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [2, 1, 3, 5, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [2, 1, 3, 5, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [2, 1, 3, 5, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [2, 1, 3, 5, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [-2, -3, -4, -5, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [-2, -3, -4, -5, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [-2, -3, -4, -5, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [-2, -3, -4, -5, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [-3, -2, -1, -6, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[1, 1, 2, 1, 2, 2],\n",
    "                [-3, -2, -1, -6, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [-3, -2, -1, -6, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [-3, -2, -1, -6, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [3, 2, 1, 3, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [3, 2, 1, 3, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [3, 2, 1, 3, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [3, 2, 1, 3, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [2, 3, 1, 5, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [2, 3, 1, 5, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [2, 3, 1, 5, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [2, 3, 1, 5, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [1, 3, 2, 5, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [1, 3, 2, 5, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [1, 3, 2, 5, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [1, 3, 2, 5, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [1, 2, 3, 6, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [1, 2, 3, 6, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [1, 2, 3, 6, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]],\n",
    "                 \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [1, 2, 3, 6, 0, 0],\n",
    "                [1, 1, 1, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [3, 2, 1, 5, 0, 0],\n",
    "                [1, 1, 0, 1, 0, 0]],\n",
    "                \n",
    "                [[2, 1, 1, 1, 1, 2],\n",
    "                [3, 2, 1, 5, 0, 0],\n",
    "                [1, 0, 1, 1, 0, 0]]])\n",
    "\n",
    "y_np = np.array([[3],\n",
    "                [3],\n",
    "                [3],\n",
    "                [3],\n",
    "                [3],\n",
    "                [3],\n",
    "                [5],\n",
    "                [5],\n",
    "                [5],\n",
    "                [5],\n",
    "                [7],\n",
    "                [7],\n",
    "                [7],\n",
    "                [7],\n",
    "                [2],\n",
    "                [2],\n",
    "                [3],\n",
    "                [2],\n",
    "                [3],\n",
    "                [1],\n",
    "                [5],\n",
    "                [1],\n",
    "                [1],\n",
    "                [1],\n",
    "                [4],\n",
    "                [1],\n",
    "                [4],\n",
    "                [4],\n",
    "                [4],\n",
    "                [4],\n",
    "                [4],\n",
    "                [2],\n",
    "                [4],\n",
    "                [4],\n",
    "                [4],\n",
    "                [2],\n",
    "                [4],\n",
    "                [4],\n",
    "                [4],\n",
    "                [4],\n",
    "                [4],\n",
    "                [5],\n",
    "                [5],\n",
    "                [5],\n",
    "                [5],\n",
    "                [5],\n",
    "                [5],\n",
    "                [5],\n",
    "                [6],\n",
    "                [1],\n",
    "                [6],\n",
    "                [6],\n",
    "                [6],\n",
    "                [6],\n",
    "                [6],\n",
    "                [6],\n",
    "                [6],\n",
    "                [6],\n",
    "                [7],\n",
    "                [7],\n",
    "                [7],\n",
    "                [7],\n",
    "                [7],\n",
    "                [7],\n",
    "                [2],\n",
    "                [2],\n",
    "                [6],\n",
    "                [2],\n",
    "                [3],\n",
    "                [3],\n",
    "                [5],\n",
    "                [5],\n",
    "                [5],\n",
    "                [5],\n",
    "                [4],\n",
    "                [2],\n",
    "                [4],\n",
    "                [4],\n",
    "                [4],\n",
    "                [4],\n",
    "                [4],\n",
    "                [1],\n",
    "                [4],\n",
    "                [5],\n",
    "                [4],\n",
    "                [4],\n",
    "                [6],\n",
    "                [6],\n",
    "                [6],\n",
    "                [6],\n",
    "                [3],\n",
    "                [3],\n",
    "                [3],\n",
    "                [3],\n",
    "                [7],\n",
    "                [7],\n",
    "                [7],\n",
    "                [7],\n",
    "                [6],\n",
    "                [6]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_np's pre-expansion shape: (100, 3, 6)\n",
      "y_np shape: (100, 1)\n",
      "X_np's shape after adding an extra dimension to conform it to have 4 dimensions: (100, 1, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "print \"X_np's pre-expansion shape: {}\".format(X_np.shape)\n",
    "print \"y_np shape: {}\".format(y_np.shape)\n",
    "\n",
    "X_np = np.expand_dims(X_np, axis = 1)\n",
    "print \"X_np's shape after adding an extra dimension to conform it to have 4 dimensions: {}\".format(X_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 6, 6, 6, 6, 1, 1, 2, 1, 2, 0, 4, 0, 0, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "def multi_class_format(numpy_array):\n",
    "    new = []\n",
    "    for item in y_np:\n",
    "        for i in item:\n",
    "            new.append(i)\n",
    "    \n",
    "    class_labels = []\n",
    "    \n",
    "    for i in new:\n",
    "        identifier = i-1\n",
    "        class_labels.append(identifier)\n",
    "        \n",
    "    return class_labels\n",
    "\n",
    "Y_array = multi_class_format(y_np)\n",
    "print Y_array[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 7 #Total number of classes an LP can belong to\n",
    "\n",
    "#Function to convert the output label vector into one hot format\n",
    "def get_one_hot(targets, nb_classes):\n",
    "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (100, 7) \n",
      "[[ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "y_one_hot = get_one_hot(Y_array, 7)\n",
    "print \"Output shape: {} \".format(y_one_hot.shape)\n",
    "print y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 80, y_train: 80 , X_test: 20 , y_test: 20 \n"
     ]
    }
   ],
   "source": [
    "# Make a train/test split using 20% test size\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np, y_one_hot, test_size=0.20, shuffle = True)\n",
    "print \"X_train: {}, y_train: {} , X_test: {} , y_test: {} \".format(X_train.shape[0], y_train.shape[0], X_test.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: torch.Size([80, 1, 3, 6]) \n",
      "Training labels shape: torch.Size([80, 7]) \n",
      "Test set shape: torch.Size([20, 1, 3, 6]) \n",
      "Test labels shape: torch.Size([20, 7]) \n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "print \"Training set shape: {} \".format(X_train.size())\n",
    "print \"Training labels shape: {} \".format(y_train.size())\n",
    "\n",
    "print \"Test set shape: {} \".format(X_test.size())\n",
    "print \"Test labels shape: {} \".format(y_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Class for CNN with 3 filters of size 3 each\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 3, kernel_size=3, stride = 1, padding = 1, dilation = 1, bias = True),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size=3, stride = 1, padding = 1, dilation = 1, bias = True),\n",
    "            nn.ReLU())\n",
    "        self.fc = nn.Linear(6*3*3, 7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "#Class for CNN with 2 filters of size 3 each\n",
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 2, kernel_size=3, stride = 1, padding = 1, dilation = 1, bias = True),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 2, out_channels = 2, kernel_size=3, stride = 1, padding = 1, dilation = 1, bias = True),\n",
    "            nn.ReLU())\n",
    "        self.fc = nn.Linear(6*3*2, 7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN2(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d (1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d (2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc): Linear(in_features=36, out_features=7)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN2()\n",
    "print cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting the training one hot vector labels into indices because PyTorch does not take one-hot vectors\n",
    "targetnp = y_train.numpy()\n",
    "idxs = np.where(targetnp > 0)[1]\n",
    "new_targets = torch.LongTensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting the test one hot vector labels into indices\n",
    "test_targetnp = y_test.numpy()\n",
    "test_idxs = np.where(test_targetnp > 0)[1]\n",
    "new_test_targets = torch.LongTensor(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a Adam optimizer\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate, weight_decay = 0)\n",
    "# create a loss function\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch: 0 Average loss: 1.9873, Training Accuracy: 4/80 (5.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 10 Average loss: 1.9490, Training Accuracy: 15/80 (18.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 20 Average loss: 1.9134, Training Accuracy: 24/80 (30.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 30 Average loss: 1.8718, Training Accuracy: 26/80 (32.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 40 Average loss: 1.8202, Training Accuracy: 34/80 (42.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 50 Average loss: 1.7572, Training Accuracy: 27/80 (33.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 60 Average loss: 1.6823, Training Accuracy: 32/80 (40.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 70 Average loss: 1.5983, Training Accuracy: 43/80 (53.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 80 Average loss: 1.5123, Training Accuracy: 41/80 (51.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 90 Average loss: 1.4377, Training Accuracy: 43/80 (53.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 100 Average loss: 1.3783, Training Accuracy: 44/80 (55.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 110 Average loss: 1.3261, Training Accuracy: 44/80 (55.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 120 Average loss: 1.2769, Training Accuracy: 45/80 (56.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 130 Average loss: 1.2267, Training Accuracy: 48/80 (60.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 140 Average loss: 1.1708, Training Accuracy: 52/80 (65.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 150 Average loss: 1.1131, Training Accuracy: 52/80 (65.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 160 Average loss: 1.0560, Training Accuracy: 55/80 (68.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 170 Average loss: 0.9987, Training Accuracy: 56/80 (70.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 180 Average loss: 0.9435, Training Accuracy: 57/80 (71.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 190 Average loss: 0.8900, Training Accuracy: 58/80 (72.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 200 Average loss: 0.8397, Training Accuracy: 60/80 (75.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 210 Average loss: 0.7925, Training Accuracy: 61/80 (76.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 220 Average loss: 0.7489, Training Accuracy: 63/80 (78.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 230 Average loss: 0.7095, Training Accuracy: 64/80 (80.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 240 Average loss: 0.6735, Training Accuracy: 65/80 (81.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 250 Average loss: 0.6417, Training Accuracy: 67/80 (83.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 260 Average loss: 0.6128, Training Accuracy: 67/80 (83.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 270 Average loss: 0.5869, Training Accuracy: 67/80 (83.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 280 Average loss: 0.5635, Training Accuracy: 68/80 (85.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 290 Average loss: 0.5419, Training Accuracy: 69/80 (86.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 300 Average loss: 0.5217, Training Accuracy: 69/80 (86.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 310 Average loss: 0.5028, Training Accuracy: 69/80 (86.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 320 Average loss: 0.4846, Training Accuracy: 70/80 (87.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 330 Average loss: 0.4670, Training Accuracy: 70/80 (87.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 340 Average loss: 0.4501, Training Accuracy: 70/80 (87.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 350 Average loss: 0.4338, Training Accuracy: 70/80 (87.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 360 Average loss: 0.4177, Training Accuracy: 70/80 (87.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 370 Average loss: 0.4021, Training Accuracy: 70/80 (87.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 380 Average loss: 0.3872, Training Accuracy: 70/80 (87.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 390 Average loss: 0.3729, Training Accuracy: 70/80 (87.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 400 Average loss: 0.3587, Training Accuracy: 70/80 (87.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 410 Average loss: 0.3446, Training Accuracy: 70/80 (87.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 420 Average loss: 0.3308, Training Accuracy: 71/80 (88.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 430 Average loss: 0.3173, Training Accuracy: 71/80 (88.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 440 Average loss: 0.3043, Training Accuracy: 72/80 (90.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 450 Average loss: 0.2916, Training Accuracy: 72/80 (90.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 460 Average loss: 0.2792, Training Accuracy: 72/80 (90.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 470 Average loss: 0.2671, Training Accuracy: 73/80 (91.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 480 Average loss: 0.2556, Training Accuracy: 73/80 (91.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 490 Average loss: 0.2445, Training Accuracy: 72/80 (90.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 500 Average loss: 0.2338, Training Accuracy: 72/80 (90.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 510 Average loss: 0.2235, Training Accuracy: 72/80 (90.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 520 Average loss: 0.2135, Training Accuracy: 73/80 (91.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 530 Average loss: 0.2038, Training Accuracy: 75/80 (93.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 540 Average loss: 0.1945, Training Accuracy: 76/80 (95.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 550 Average loss: 0.1854, Training Accuracy: 76/80 (95.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 560 Average loss: 0.1768, Training Accuracy: 76/80 (95.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 570 Average loss: 0.1686, Training Accuracy: 76/80 (95.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 580 Average loss: 0.1607, Training Accuracy: 77/80 (96.2500%)\n",
      "\n",
      "\n",
      "Training Epoch: 590 Average loss: 0.1530, Training Accuracy: 78/80 (97.5000%)\n",
      "\n",
      "\n",
      "Training Epoch: 600 Average loss: 0.1457, Training Accuracy: 79/80 (98.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 610 Average loss: 0.1387, Training Accuracy: 79/80 (98.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 620 Average loss: 0.1321, Training Accuracy: 79/80 (98.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 630 Average loss: 0.1257, Training Accuracy: 79/80 (98.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 640 Average loss: 0.1196, Training Accuracy: 79/80 (98.7500%)\n",
      "\n",
      "\n",
      "Training Epoch: 650 Average loss: 0.1137, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 660 Average loss: 0.1082, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 670 Average loss: 0.1029, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 680 Average loss: 0.0980, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 690 Average loss: 0.0933, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 700 Average loss: 0.0888, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 710 Average loss: 0.0846, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 720 Average loss: 0.0806, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 730 Average loss: 0.0768, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 740 Average loss: 0.0732, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 750 Average loss: 0.0698, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 760 Average loss: 0.0666, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 770 Average loss: 0.0635, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 780 Average loss: 0.0607, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 790 Average loss: 0.0579, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 800 Average loss: 0.0553, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 810 Average loss: 0.0529, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 820 Average loss: 0.0506, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 830 Average loss: 0.0484, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 840 Average loss: 0.0464, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 850 Average loss: 0.0444, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 860 Average loss: 0.0426, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 870 Average loss: 0.0409, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 880 Average loss: 0.0392, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 890 Average loss: 0.0377, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 900 Average loss: 0.0362, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 910 Average loss: 0.0348, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 920 Average loss: 0.0334, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 930 Average loss: 0.0321, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 940 Average loss: 0.0309, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 950 Average loss: 0.0297, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 960 Average loss: 0.0286, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 970 Average loss: 0.0275, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 980 Average loss: 0.0265, Training Accuracy: 80/80 (100.0000%)\n",
      "\n",
      "\n",
      "Training Epoch: 990 Average loss: 0.0255, Training Accuracy: 80/80 (100.0000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the main training loop\n",
    "epochs = 1000\n",
    "train_loss = 0\n",
    "train_correct = 0\n",
    "test_correct = 0\n",
    "for epoch in range(epochs):\n",
    "        data, target = Variable(X_train), Variable(new_targets)\n",
    "        optimizer.zero_grad()\n",
    "        net_out = cnn(data)\n",
    "        #print net_out\n",
    "        #print target.data\n",
    "        \n",
    "        #sum up the loss\n",
    "        train_loss = loss_func(net_out, target)\n",
    "        pred = net_out.data.max(1)[1] #get the index of the max log probabitlity\n",
    "        train_correct = pred.eq(target.data).sum()\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print('\\nTraining Epoch: {} Average loss: {:.4f}, Training Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        epoch, train_loss.data[0], train_correct, len(target),\n",
    "        100. * train_correct / len(target)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 1.7864, Test accuracy: 15/20 (75.0000%)\n",
      "\n",
      "Time taken to detect:  0.000709056854248\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "test_correct = 0\n",
    "\n",
    "#Converting test data and target labels into pyTorch variables\n",
    "test_data, test_target = Variable(X_test), Variable(new_test_targets)\n",
    "\n",
    "tic = time.time()\n",
    "#Test set output\n",
    "net_out = cnn(test_data)\n",
    "\n",
    "test_loss = loss_func(net_out, test_target)\n",
    "test_pred = net_out.data.max(1)[1] #get the index of max log probability\n",
    "test_correct = test_pred.eq(test_target.data).sum()\n",
    "\n",
    "toc = time.time()\n",
    "time_diff = toc - tic\n",
    "\n",
    "print('\\nTest loss: {:.4f}, Test accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "    test_loss.data[0], test_correct, len(test_target), 100. * test_correct / len(test_target)))\n",
    "\n",
    "print \"Time taken to detect: \", time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
